{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf23eb19",
   "metadata": {},
   "source": [
    "# Aggregation of Pre-trained Models\n",
    "\n",
    "## Steps\n",
    "\n",
    "1. Complete model training in `training_demo.ipynb`\n",
    "2. Load pre-trained models from experiments\n",
    "3. Configure aggregation methods and weights\n",
    "4. Run aggregation experiments with different sample sizes\n",
    "5. Evaluate aggregated predictions using survival metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "052a4c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import copy\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append('../src')\n",
    "from aggregation.PredictionsAggregator import PredictionsAggregator\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea06206d",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Setup aggregation experiment parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62c09935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment configuration\n",
    "DATASET_TRAIN_SAMPLES = 20 # Number of samples in dataset which will be used as a train dataset\n",
    "MODEL_TRAIN_SAMPLES = 20 # Number of samples the model was trained on (for model selection)\n",
    "SAMPLE_GRID = [1, 5, 10]  # Number of samples for aggregation\n",
    "TEST_SAMPLES = [25]\n",
    "MODELS_SIZE = [2048] # Hidden size of the model (for model selection)\n",
    "MODEL_NAME = 'CoxTV'\n",
    "METRICS_LIST = {'ci', 'ibs'}\n",
    "DATA_EXT = '.csv'\n",
    "\n",
    "DATA_FOLDER = Path(\"Data/Preprocessed\") # Path to preprocessed data\n",
    "RES_FOLDER = Path(f\"Data/Agg\")\n",
    "MODELS_FOLDER = Path(f\"demo_models\") # Path to trained models for aggregation demo\n",
    "\n",
    "TIMES = np.arange(0, 730)\n",
    "TRAIN_BATCHSIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd84ab9e",
   "metadata": {},
   "source": [
    "## Aggregation Methods\n",
    "\n",
    "Define different prediction aggregation strategies with various weight distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5420c2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregation methods configured:\n",
      "- n_dist: ['0.01', '0.1', '0.3', '0.5', '0.7', '0.9', '0.99']\n",
      "- t_dist: ['0.1', '1', '10', '25', '50', '100', '1000']\n",
      "- geom: ['0.01', '0.1', '0.3', '0.5', '0.7', '0.9', '0.99']\n"
     ]
    }
   ],
   "source": [
    "# Define aggregation methods with different weights using real PredictionsAggregator\n",
    "AGGREGATORS_DICT = {\n",
    "    \"n_dist\": {\n",
    "        \"0.01\": PredictionsAggregator(mode='n_dist', weight=0.01),\n",
    "        \"0.1\": PredictionsAggregator(mode='n_dist', weight=0.1),\n",
    "        \"0.3\": PredictionsAggregator(mode='n_dist', weight=0.3),\n",
    "        \"0.5\": PredictionsAggregator(mode='n_dist', weight=0.5),\n",
    "        \"0.7\": PredictionsAggregator(mode='n_dist', weight=0.7),\n",
    "        \"0.9\": PredictionsAggregator(mode='n_dist', weight=0.9),\n",
    "        \"0.99\": PredictionsAggregator(mode='n_dist', weight=0.99)\n",
    "    },\n",
    "    \"t_dist\": {\n",
    "        \"0.1\": PredictionsAggregator(mode='t_dist', weight=0.1),\n",
    "        \"1\": PredictionsAggregator(mode='t_dist', weight=1),\n",
    "        \"10\": PredictionsAggregator(mode='t_dist', weight=10),\n",
    "        \"25\": PredictionsAggregator(mode='t_dist', weight=25),\n",
    "        \"50\": PredictionsAggregator(mode='t_dist', weight=50),\n",
    "        \"100\": PredictionsAggregator(mode='t_dist', weight=100),\n",
    "        \"1000\": PredictionsAggregator(mode='t_dist', weight=1000)\n",
    "    },\n",
    "    \"geom\": {\n",
    "        \"0.01\": PredictionsAggregator(mode='geom', weight=0.01),\n",
    "        \"0.1\": PredictionsAggregator(mode='geom', weight=0.1),\n",
    "        \"0.3\": PredictionsAggregator(mode='geom', weight=0.3),\n",
    "        \"0.5\": PredictionsAggregator(mode='geom', weight=0.5),\n",
    "        \"0.7\": PredictionsAggregator(mode='geom', weight=0.7),\n",
    "        \"0.9\": PredictionsAggregator(mode='geom', weight=0.9),\n",
    "        \"0.99\": PredictionsAggregator(mode='geom', weight=0.99)\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"Aggregation methods configured:\")\n",
    "for method, variants in AGGREGATORS_DICT.items():\n",
    "    print(f\"- {method}: {list(variants.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7a3dfe",
   "metadata": {},
   "source": [
    "## Functions from Agg.py\n",
    "\n",
    "Import and setup key functions for aggregation experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "128c27d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions for aggregation experiments  \n",
    "from train_scripts.Agg import eval_model\n",
    "\n",
    "def create_demo_schema(metrics_list):\n",
    "    \"\"\"Create schema for demo aggregation results\"\"\"\n",
    "    base_schema = {\n",
    "        'train_samples': [],\n",
    "        'agg_samples': [],\n",
    "        'method': [],\n",
    "        'agg_method': [],\n",
    "        'agg_weight': [],\n",
    "        'model_id': []\n",
    "    }\n",
    "    \n",
    "    schema = copy.deepcopy(base_schema)\n",
    "    for metric in metrics_list:\n",
    "        schema[f'{metric}_train'] = []\n",
    "        schema[f'{metric}_test'] = []\n",
    "    \n",
    "    return schema\n",
    "\n",
    "def save_results_to_csv(results_df, filename):\n",
    "    \"\"\"Save aggregation results to CSV file\"\"\"\n",
    "    results_df.to_csv(filename, index=False)\n",
    "    print(f\"Results saved to {filename}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5833933f",
   "metadata": {},
   "source": [
    "## Model Loading and Data Preparation\n",
    "\n",
    "Load pre-trained models and prepare test data for aggregation experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5f5fead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 trained models:\n",
      "  - 0_CoxTV.pkl\n"
     ]
    }
   ],
   "source": [
    "# Create directories for demo results\n",
    "RES_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "MODELS_FOLDER.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create demo results schema\n",
    "SCHEMA = create_demo_schema(METRICS_LIST)\n",
    "results_filename = RES_FOLDER / f\"aggregation_results_{DATASET_TRAIN_SAMPLES}_{max(SAMPLE_GRID)}.csv\"\n",
    "\n",
    "# Look for trained models from training demo\n",
    "model_files = list(MODELS_FOLDER.glob(\"*.pkl\"))\n",
    "if not model_files:\n",
    "    raise FileNotFoundError(f\"No trained models found in {MODELS_FOLDER}. Please run training_demo.ipynb first.\")\n",
    "\n",
    "print(f\"Found {len(model_files)} trained models:\")\n",
    "for model_file in model_files:\n",
    "    print(f\"  - {model_file.name}\")\n",
    "\n",
    "# Create model_name_grid from all available models\n",
    "model_name_grid = [model_file.stem for model_file in model_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad7330e",
   "metadata": {},
   "source": [
    "## Run Aggregation Experiments\n",
    "\n",
    "Execute aggregation experiments with different methods and sample sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68aac9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model 1/1: 0_CoxTV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting data for Cox prediction: 100%|██████████| 3336/3336 [00:07<00:00, 420.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начало обработки 1 n_samples\n",
      "Обработка 1 завершена за 20.681692838668823 секунд\n",
      "Начало обработки 5 n_samples\n",
      "Обработка 5 завершена за 152.42873120307922 секунд\n",
      "Начало обработки 10 n_samples\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(model_name_grid)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m     model_results \u001b[38;5;241m=\u001b[39m \u001b[43meval_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtest_data_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_folder\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mDATA_FOLDER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodels_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMODELS_FOLDER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43magg_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mAGGREGATORS_DICT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetrics_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMETRICS_LIST\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_grid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSAMPLE_GRID\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mTIMES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_train_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mMODEL_TRAIN_SAMPLES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_batchsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTRAIN_BATCHSIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric_postfix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_ext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDATA_EXT\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m completed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(model_results)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m results\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m     all_results\u001b[38;5;241m.\u001b[39mappend(model_results)\n",
      "File \u001b[0;32m~/TV-Survival/demo/../src/train_scripts/Agg.py:252\u001b[0m, in \u001b[0;36meval_model\u001b[0;34m(data_path, data_folder, models_folder, model_name, agg_dict, metrics_list, sample_grid, times, model_train_samples, metric_postfix, data_ext, train_batchsize)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m agg_dict:\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m weight \u001b[38;5;129;01min\u001b[39;00m agg_dict[method]:\n\u001b[0;32m--> 252\u001b[0m         result_row \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magg_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mcur_timeshift\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_X_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcur_X_gt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_train_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mmetric_postfix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_train_gt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m         results_list\u001b[38;5;241m.\u001b[39mappend(result_row)\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mОбработка \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m завершена за \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mtime_start\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m секунд\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/TV-Survival/demo/../src/train_scripts/Agg.py:123\u001b[0m, in \u001b[0;36mcalculate_metrics\u001b[0;34m(model, predictions_aggregator, scorer, method, weight, n_samples, timeshift, X, X_gt, model_name, model_train_samples, times, metric_postfix, metrics_list, df_train_gt)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcalculate_metrics\u001b[39m(model, predictions_aggregator, scorer, method, weight, n_samples, timeshift, X, X_gt, model_name, model_train_samples, times, metric_postfix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics_list\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mci\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mibs\u001b[39m\u001b[38;5;124m'\u001b[39m], df_train_gt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 123\u001b[0m     aggregated_pred \u001b[38;5;241m=\u001b[39m \u001b[43mpredictions_aggregator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeshift\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeshift\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m scorer\u001b[38;5;241m.\u001b[39mget_metrics(\n\u001b[1;32m    126\u001b[0m         model, aggregated_pred, X_gt, times,\n\u001b[1;32m    127\u001b[0m         metrics\u001b[38;5;241m=\u001b[39mmetrics_list,\n\u001b[1;32m    128\u001b[0m         df_train\u001b[38;5;241m=\u001b[39mdf_train_gt)\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;66;03m# Формируем запись результата\u001b[39;00m\n",
      "File \u001b[0;32m~/TV-Survival/demo/../src/aggregation/PredictionsAggregator.py:71\u001b[0m, in \u001b[0;36mPredictionsAggregator.predict\u001b[0;34m(self, X_pred, times, timeshift)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeom\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     70\u001b[0m     pred_corrected\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurv_prob\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgeom_agg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_corrected\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprob_dist\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprob_dist_agg(pred_corrected)\n",
      "File \u001b[0;32m~/TV-Survival/demo/../src/aggregation/PredictionsAggregator.py:193\u001b[0m, in \u001b[0;36mPredictionsAggregator.geom_agg\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    190\u001b[0m result_df\u001b[38;5;241m.\u001b[39mloc[powers \u001b[38;5;241m!=\u001b[39m result_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid_col)\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha\n\u001b[1;32m    192\u001b[0m time_columns \u001b[38;5;241m=\u001b[39m result_df\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid_col, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_col, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m--> 193\u001b[0m \u001b[43mresult_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_columns\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m result_df\u001b[38;5;241m.\u001b[39mloc[:, time_columns]\u001b[38;5;241m.\u001b[39mmul(\n\u001b[1;32m    194\u001b[0m     result_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrows\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    195\u001b[0m result_df \u001b[38;5;241m=\u001b[39m result_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid_col)[time_columns]\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mdiv(\n\u001b[1;32m    196\u001b[0m     result_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid_col)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum(), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrows\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    198\u001b[0m result_df\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_col] \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid_col)[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_col]\u001b[38;5;241m.\u001b[39mmax()\n",
      "File \u001b[0;32m~/TV-Survival/venv/lib/python3.8/site-packages/pandas/core/indexing.py:818\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    817\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[0;32m--> 818\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/TV-Survival/venv/lib/python3.8/site-packages/pandas/core/indexing.py:1795\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1792\u001b[0m \u001b[38;5;66;03m# align and set the values\u001b[39;00m\n\u001b[1;32m   1793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m take_split_path:\n\u001b[1;32m   1794\u001b[0m     \u001b[38;5;66;03m# We have to operate column-wise\u001b[39;00m\n\u001b[0;32m-> 1795\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_split_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1796\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1797\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
      "File \u001b[0;32m~/TV-Survival/venv/lib/python3.8/site-packages/pandas/core/indexing.py:1831\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1828\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like_indexer(value) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(value, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1830\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, ABCDataFrame):\n\u001b[0;32m-> 1831\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_frame_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1833\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mndim(value) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   1834\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_with_indexer_2d_value(indexer, value)\n",
      "File \u001b[0;32m~/TV-Survival/venv/lib/python3.8/site-packages/pandas/core/indexing.py:1955\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_frame_value\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1953\u001b[0m     val \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnan\n\u001b[0;32m-> 1955\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_single_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpi\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/TV-Survival/venv/lib/python3.8/site-packages/pandas/core/indexing.py:1996\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_single_column\u001b[0;34m(self, loc, value, plane_indexer)\u001b[0m\n\u001b[1;32m   1993\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n\u001b[1;32m   1994\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m-> 1996\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iset_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1998\u001b[0m \u001b[38;5;66;03m# We will not operate in-place, but will attempt to in the future.\u001b[39;00m\n\u001b[1;32m   1999\u001b[0m \u001b[38;5;66;03m#  To determine whether we need to issue a FutureWarning, see if the\u001b[39;00m\n\u001b[1;32m   2000\u001b[0m \u001b[38;5;66;03m#  setting in-place would work, i.e. behavior will change.\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_column_array(loc)\n",
      "File \u001b[0;32m~/TV-Survival/venv/lib/python3.8/site-packages/pandas/core/frame.py:4156\u001b[0m, in \u001b[0;36mDataFrame._iset_item\u001b[0;34m(self, loc, value)\u001b[0m\n\u001b[1;32m   4154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_iset_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, loc: \u001b[38;5;28mint\u001b[39m, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4155\u001b[0m     arraylike \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sanitize_column(value)\n\u001b[0;32m-> 4156\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iset_item_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marraylike\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   4158\u001b[0m     \u001b[38;5;66;03m# check if we are modifying a copy\u001b[39;00m\n\u001b[1;32m   4159\u001b[0m     \u001b[38;5;66;03m# try to set first as we want an invalid\u001b[39;00m\n\u001b[1;32m   4160\u001b[0m     \u001b[38;5;66;03m# value exception to occur first\u001b[39;00m\n\u001b[1;32m   4161\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n",
      "File \u001b[0;32m~/TV-Survival/venv/lib/python3.8/site-packages/pandas/core/frame.py:4136\u001b[0m, in \u001b[0;36mDataFrame._iset_item_mgr\u001b[0;34m(self, loc, value, inplace)\u001b[0m\n\u001b[1;32m   4132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_iset_item_mgr\u001b[39m(\n\u001b[1;32m   4133\u001b[0m     \u001b[38;5;28mself\u001b[39m, loc: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mslice\u001b[39m \u001b[38;5;241m|\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray, value, inplace: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   4134\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4135\u001b[0m     \u001b[38;5;66;03m# when called from _set_item_mgr loc can be anything returned from get_loc\u001b[39;00m\n\u001b[0;32m-> 4136\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[0;32m~/TV-Survival/venv/lib/python3.8/site-packages/pandas/core/internals/managers.py:1268\u001b[0m, in \u001b[0;36mBlockManager.iset\u001b[0;34m(self, loc, value, inplace)\u001b[0m\n\u001b[1;32m   1266\u001b[0m     removed_blknos\u001b[38;5;241m.\u001b[39mappend(blkno_l)\n\u001b[1;32m   1267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1268\u001b[0m     nb \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblk_locs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1269\u001b[0m     blocks_tup \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1270\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks[:blkno_l] \u001b[38;5;241m+\u001b[39m (nb,) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks[blkno_l \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m :]\n\u001b[1;32m   1271\u001b[0m     )\n\u001b[1;32m   1272\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m blocks_tup\n",
      "File \u001b[0;32m~/TV-Survival/venv/lib/python3.8/site-packages/pandas/core/internals/blocks.py:1921\u001b[0m, in \u001b[0;36mNumpyBlock.delete\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdelete\u001b[39m(\u001b[38;5;28mself\u001b[39m, loc) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Block:\n\u001b[0;32m-> 1921\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1922\u001b[0m     mgr_locs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr_locs\u001b[38;5;241m.\u001b[39mdelete(loc)\n\u001b[1;32m   1923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(values, placement\u001b[38;5;241m=\u001b[39mmgr_locs, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim)\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mdelete\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/TV-Survival/venv/lib/python3.8/site-packages/numpy/lib/function_base.py:5223\u001b[0m, in \u001b[0;36mdelete\u001b[0;34m(arr, obj, axis)\u001b[0m\n\u001b[1;32m   5221\u001b[0m     slobj2 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)]\u001b[38;5;241m*\u001b[39mndim\n\u001b[1;32m   5222\u001b[0m     slobj2[axis] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(obj\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 5223\u001b[0m     \u001b[43mnew\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mslobj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m arr[\u001b[38;5;28mtuple\u001b[39m(slobj2)]\n\u001b[1;32m   5224\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5225\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Prepare test data path\n",
    "test_data_path = DATA_FOLDER / f\"{DATASET_TRAIN_SAMPLES}_{TEST_SAMPLES[0]}_test_preprocessed{DATA_EXT}\"\n",
    "\n",
    "# Run evaluation for each model and collect results\n",
    "all_results = []\n",
    "\n",
    "for i, model_name in enumerate(model_name_grid, 1):\n",
    "    print(f\"Processing model {i}/{len(model_name_grid)}: {model_name}\")\n",
    "    try:\n",
    "        model_results = eval_model(\n",
    "            data_path=str(test_data_path),\n",
    "            data_folder = DATA_FOLDER,\n",
    "            models_folder=MODELS_FOLDER,\n",
    "            model_name=model_name,\n",
    "            agg_dict=AGGREGATORS_DICT,\n",
    "            metrics_list=METRICS_LIST,\n",
    "            sample_grid=SAMPLE_GRID,\n",
    "            times = TIMES,\n",
    "            model_train_samples= MODEL_TRAIN_SAMPLES,\n",
    "            train_batchsize=TRAIN_BATCHSIZE,\n",
    "            metric_postfix='test',\n",
    "            data_ext=DATA_EXT\n",
    "        )\n",
    "        \n",
    "        print(f\"Model {model_name} completed: {len(model_results)} results\")\n",
    "        all_results.append(model_results)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing model {model_name}: {e}\")\n",
    "        continue\n",
    "\n",
    "# Combine all results into one dataframe\n",
    "if all_results:\n",
    "    results_df = pd.concat(all_results, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1dafd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
