{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b0e44f6",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "## Steps\n",
    "\n",
    "1. Complete data preprocessing in `preprocessing_demo.ipynb`\n",
    "2. Configure training parameters \n",
    "3. Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44086ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "sys.path.append('../src')\n",
    "\n",
    "from train_scripts.Experiments import (\n",
    "    TrainingConfig, DataConfig, ExperimentConfig,\n",
    "    prepare_dataloader, run_single_experiment, \n",
    "    make_schema, collect_all_hparams, ModelScorer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6dd3b6",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Setup parameters for experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843b0e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample sizes\n",
    "TRAIN_GRID = [20]  \n",
    "TEST_GRID = [25]   \n",
    "VALIDATION_SIZE = 10  \n",
    "\n",
    "# Model parameters\n",
    "PARAM_GRIDS = {\n",
    "    \"SP\": ParameterGrid({\n",
    "        \"hidden_dim\": [2048], \n",
    "    }),\n",
    "    \n",
    "    \"CoxTV\": ParameterGrid({\n",
    "        \"penalizer\": [np.logspace(-2, 2, 5)[1]], \n",
    "        \"l1_ratio\": [np.logspace(-2, 2, 5)[1]]   \n",
    "    }),\n",
    "}\n",
    "\n",
    "# Data\n",
    "DATA_FOLDER = \"../Data\"  \n",
    "TRAIN_BATCH_SIZE = 64   \n",
    "SCORE_BATCH_SIZE = 128  \n",
    "\n",
    "# Time\n",
    "TIMES = np.arange(0, 730)   \n",
    "TRAIN_TIMES = TIMES[::10]   \n",
    "\n",
    "# Training\n",
    "EPOCHS = 20             \n",
    "LEARNING_RATE = 1e-3    \n",
    "EARLY_STOPPING = True   \n",
    "PATIENCE = 5            \n",
    "MIN_DELTA = 0.001       \n",
    "SCORE_METRIC = \"ibs\"    \n",
    "\n",
    "# Metrics\n",
    "METRICS = [\"ci\", \"ibs\"]  \n",
    "\n",
    "METHODS = list(PARAM_GRIDS.keys())\n",
    "\n",
    "print(\"Ready:\")\n",
    "print(f\"  Methods: {METHODS}\")\n",
    "print(f\"  Data: {TRAIN_GRID} train, {TEST_GRID} test\")\n",
    "print(f\"  Metrics: {METRICS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e40a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create configurations\n",
    "data_cfg = DataConfig(\n",
    "    data_folder=DATA_FOLDER,\n",
    "    train_batchsize=TRAIN_BATCH_SIZE,\n",
    "    score_batchsize=SCORE_BATCH_SIZE,\n",
    "    times=TIMES,\n",
    "    train_times=TRAIN_TIMES,\n",
    "    to_cens_shift=[], \n",
    "    to_term_shift=[], \n",
    "    cens_prob=-1,      \n",
    ")\n",
    "\n",
    "train_cfg = TrainingConfig(\n",
    "    epochs=EPOCHS,\n",
    "    lr=LEARNING_RATE,\n",
    "    early_stopping=EARLY_STOPPING,\n",
    "    patience=PATIENCE,\n",
    "    min_delta=MIN_DELTA,\n",
    "    score_metric=SCORE_METRIC,\n",
    ")\n",
    "\n",
    "all_hparams = collect_all_hparams(PARAM_GRIDS)\n",
    "schema = make_schema(METRICS, all_hparams)\n",
    "\n",
    "exp_cfg = ExperimentConfig(\n",
    "    metrics=METRICS,\n",
    "    schema=schema,\n",
    "    res_filename=\"demo_results.csv\", \n",
    "    models_folder=\"demo_models\",     \n",
    "    log_dir=\"demo_logs\",            \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f27f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "scorer = ModelScorer()\n",
    "max_train_samples = max(TRAIN_GRID)\n",
    "\n",
    "dl_score_max = prepare_dataloader(\n",
    "    train_samples=max_train_samples,\n",
    "    data_cfg=data_cfg,\n",
    "    data_type=\"train\",\n",
    "    dataset_type=\"score\"\n",
    ")\n",
    "\n",
    "df_train_max = pd.read_csv(f\"{DATA_FOLDER}/{max_train_samples}_train_preprocessed.csv\")\n",
    "df_train_max[\"duration\"] = df_train_max[\"max_lifetime\"] - df_train_max[\"time\"]\n",
    "df_train_max = df_train_max[[\"duration\", \"failure\", \"time\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb7f751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run experiments\n",
    "all_results = []\n",
    "run_id = 0\n",
    "\n",
    "for train_samples in TRAIN_GRID:\n",
    "    for method in METHODS:\n",
    "        for hparams in PARAM_GRIDS[method]:\n",
    "            print(f\"Running {method} with {hparams}\")\n",
    "            \n",
    "            try:\n",
    "                result = run_single_experiment(\n",
    "                    train_samples=train_samples,\n",
    "                    test_grid=TEST_GRID,\n",
    "                    method=method,\n",
    "                    hparams=hparams,\n",
    "                    run_id=run_id,\n",
    "                    scorer=scorer,\n",
    "                    dl_score_max=dl_score_max,\n",
    "                    df_train_max=df_train_max,\n",
    "                    exp_cfg=exp_cfg,\n",
    "                    data_cfg=data_cfg,\n",
    "                    train_cfg=train_cfg,\n",
    "                    val_data_size=VALIDATION_SIZE,\n",
    "                )\n",
    "                \n",
    "                all_results.append(result)\n",
    "                \n",
    "                if result[\"error\"][0] == 0:\n",
    "                    print(f\"Success! Training time: {result['train_time'][0]:.2f}s\")\n",
    "                    for metric in METRICS:\n",
    "                        train_val = result[f'{metric}_train_same_size'][0]\n",
    "                        test_val = result[f'{metric}_test'][0]\n",
    "                        print(f\"  {metric}: train={train_val:.4f}, test={test_val:.4f}\")\n",
    "                else:\n",
    "                    print(f\"Failed: {result['error_text'][0]}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Failed: {str(e)}\")\n",
    "                \n",
    "            run_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcaed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "if all_results:\n",
    "    results_df = pd.DataFrame({\n",
    "        k: [r[k][0] for r in all_results] \n",
    "        for k in all_results[0].keys()\n",
    "    })\n",
    "    \n",
    "    print(\"Results:\")\n",
    "    print(results_df.to_string(index=False, float_format='%.4f'))\n",
    "    \n",
    "else:\n",
    "    print(\"No experiments were run.\")\n",
    "    print(\"Check that preprocessed data files exist in DATA_FOLDER.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72a0441",
   "metadata": {},
   "source": [
    "## Done\n",
    "\n",
    "Training completed.\n",
    "To modify experiments, change `PARAM_GRIDS`, `TRAIN_GRID`, `EPOCHS`, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
