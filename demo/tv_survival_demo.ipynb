{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b4f5a94",
   "metadata": {},
   "source": [
    "# TV-Survival System Demo\n",
    "\n",
    "Step-by-step sequence to reproduce results from the accompanying research paper.\n",
    "\n",
    "## Pipeline Steps\n",
    "\n",
    "1. **Download Dataset** \n",
    "2. **Convert to Parquet** - `datastats2parquet.py`\n",
    "3. **Truncate Data** - `truncate.py`  \n",
    "4. **Split Dataset** - `Splitter.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2baf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append('../src')\n",
    "\n",
    "raw_data_dir = Path('../RawData')\n",
    "data_dir = Path('../Data')\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "raw_data_dir.mkdir(exist_ok=True)\n",
    "data_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac58a41",
   "metadata": {},
   "source": [
    "## Step 1: Download Dataset\n",
    "\n",
    "In this step, we download the raw dataset.\n",
    "The following cells will download the required dataset files using wget commands. Make sure you have sufficient disk space available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7309a7",
   "metadata": {
    "vscode": {
     "languageId": "bash"
    }
   },
   "outputs": [],
   "source": [
    "# Navigate to data directory\n",
    "cd ../RawData\n",
    "\n",
    "# wget \"URL_TO_2016_DATA\"\n",
    "# wget \"URL_TO_2017_DATA\"\n",
    "# wget \"URL_TO_FAILURE_DATA\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a428612",
   "metadata": {},
   "source": [
    "## Step 2: Convert Data Statistics to Parquet\n",
    "\n",
    "The `datastats2parquet.py` script converts raw CSV data files into Parquet format. This step unzips archives and concatenates data. Set `unique_ids` higher than the actual number of drives to ensure all drives are included in the final file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d1eb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datastats2parquet import main as unzip_and_agg\n",
    "unzip_and_agg(data_folder='.', unique_ids=5000, frequency=1, sample_file='2016.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b41004",
   "metadata": {},
   "source": [
    "## Step 3: Truncate Data\n",
    "\n",
    "The `truncate.py` script processes the converted Parquet data to handle truncation. Truncated drives are those that are censored only because the observation period ended (right-censored observations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc04a312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from truncate import truncate_observations\n",
    "truncate_observations(input_file='merged.parquet', output_file='2016_2018_trunc.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15ef472",
   "metadata": {},
   "source": [
    "## Step 4: Split Dataset\n",
    "\n",
    "The `Splitter.py` script performs the final preprocessing step by applying the complete preprocessing pipeline and splitting the data:\n",
    "\n",
    "- **Stratified sampling**: Creates balanced train/test splits preserving failure rate distribution (train and test sets do not overlap by drives)\n",
    "- **Feature engineering**: Applies time transformations, aggregation, and scaling\n",
    "- **Multiple sample sizes**: Generates datasets with different numbers of observations per drive\n",
    "- **Quality control**: Removes drives with insufficient data or anomalous patterns\n",
    "\n",
    "This step produces the final preprocessed datasets ready for survival model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87210dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Splitter import main as split_data\n",
    "split_data(input_file='2016_2018_trunc.parquet')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
